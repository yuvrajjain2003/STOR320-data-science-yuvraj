---
title: "Homework 6"
author: "Yuvraj Jain"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Instructions

**Exercises:**  4 (Pg. 302); 1 (Pgs. 316-317); 1 (Pgs. 328-329); 1, 2 (Pgs. 353-354)

**Submission:** Submit via an electronic document on Sakai. Must be submitted as a HTML file generated in RStudio. All assigned problems are chosen according to the textbook *R for Data Science*. You do not need R code to answer every question. If you answer without using R code, delete the code chunk. If the question requires R code, make sure you display R code. If the question requires a figure, make sure you display a figure. A lot of the questions can be answered in written response, but require R code and/or figures for understanding and explaining.

```{r, include=FALSE}
library(tidyverse)
library(nycflights13)
```

# Chapter 16 (Pg. 302)

##  Exercise 4: Create functions that take a vector as input and return:

### a) The last value. Should you use [ or [[ ?

```{r}
last_value <- function(x) {
  # check for case with no length
  if (length(x) != 0) {
    x[[length(x)]]
  } else {
    x
  }
}

last_value(1:10)
```

The function uses `[[` in order to extract a single element.

### b) The elements at even numbered positions.

```{r}
even_positions <- function(x) {
   if (length(x) != 0) {
    x[seq_along(x) %% 2 == 0]
  } else {
    x
  }
}

even_positions(1:10)
```

### c) Every element except the last value.

```{r}
except_last <- function(x) {
  if (length(x) != 0) {
    x[1:length(x)-1]
  } else {
    x
  }
}

except_last(1:10)
```

### d) Only even numbers (and no missing values)

```{r}
even_numbers <- function(x) {
  x[x %% 2 == 0]
}

even_numbers(1:10)
```

# Chapter 17 (Pgs. 316-317)

##  Exercise 1: Write for loops to:

### a) Compute the mean of every column in `mtcars`

```{r}
output <- vector("double", ncol(mtcars))
for (i in seq_along(mtcars)) {
  output[i] <- mean(mtcars[,i])
}
output
```

### b) Determine the type of each column in nyc flights13::flights

```{r}
output <- vector("character", ncol(flights))
for (i in seq_along(flights)) {
  col_class <- class(flights[[i]])
  if (length(col_class) == 1) {
    output[i] <- col_class
  } else {
    output[i] <- paste0(col_class, collapse = "/")
  }
}
```

### c) Compute the number of unuique values in each column of `iris`

```{r}
data("iris")
output <- vector("double", ncol(iris))
names(output) <- names(iris)
for (i in names(iris)) {
  output[i] <- length(unique(iris[,i]))
}
output
```

### d) Generate 10 random normals for each of $\mu = -10, 0, 10,$ and $100$. Think about the output, sequence, and body before you start writing the loop. 

```{r}
mu <- c(-10, 0, 10, 100)
output <- vector("list", 4)
for (i in seq_along(output)) {
  output[[i]] <- rnorm(10, mean = mu[i])
}
output
```

# Chapter 17 (Pgs. 328-329)

##  Exercise 1: Write code that uses one of the map functions to:

### a) Compute the mean of every column in `mtcars`

```{r}
map_dbl(mtcars, mean)
```

### b)
```{r}
map_chr(flights, typeof)
```

### c)
```{r}
map_int(iris, n_distinct)
```

### d)
```{r}
map(c(-10, 0, 10, 100), ~rnorm(n = 10, mean = .))
```

# Chapter 18 (Pgs. 353-354)

##  Exercise 1:

One downside of the linear model is that it is sensitive to unusual values because the distance incorporates a squared term. Fit a linear model to the following simulated data, and visualize the results. Rerun a few times to generate different simulated datasets. What do you notice about the model?

```{r}
sim1a <- tibble(
  x = rep(1:10, each = 3),
  y = x * 1.5 + 6 + rt(length(x), df = 2)
)
head(sim1a)
```

Runnning it once to see the results:

```{r}
ggplot(sim1a, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

Running the code a few times, a noticed that the slope gets skewed a lot by the outliers. Especially the y values when x = 10.0. If these values are really low or really high, the slope can vary by a lot. 

##  Exercise 2: 

One way to make linear models more robust is to use a different distance measure. For example, instead of root-mean-squared distance, you could use mean-absolute distance:
        
Use optim() to fit this model to the previous simulated data and compare it to the linear model.

```{r}
measure_distance <- function(mod, data) {
          diff <- data$y - make_prediction(mod, data)
          mean(abs(diff))
}
```

For the above function to work, we need to define a function, make_prediction(), that takes a numeric vector of length two (the intercept and slope) and returns the predictions,

```{r}
make_prediction <- function(mod, data) {
  mod[1] + mod[2] * data$x
}
```

Using the sim1a data, the best parameters of the least absolute deviation are:

```{r}
best <- optim(c(0, 0), measure_distance, data = sim1a)
best$par
```

Using the sim1a data, while the parameters the minimize the least squares objective function are:

```{r}
measure_distance_ls <- function(mod, data) {
  diff <- data$y - (mod[1] + mod[2] * data$x)
  sqrt(mean(diff^2))
}

best <- optim(c(0, 0), measure_distance_ls, data = sim1a)
best$par
```

